"""ExploitAgent for guided exploitation with blast radius and evidence validation (EXPL-01 through EXPL-04).

Provides:
- ExploitAgent: Orchestrates multi-step exploitation chains with user approval
- ExploitStep: Single step in exploitation chain with blast radius info
- ExploitChain: Multi-step exploit chain linked to a finding
- ExploitResult: Results of executing an exploit chain

Implements guided exploitation workflow:
1. Takes vulnerability findings from VulnAgent
2. Suggests multi-step exploit chains based on finding type (EXPL-01)
3. Displays blast radius before each destructive step (EXPL-02)
4. Requires user approval at each moderate/destructive step
5. Generates reproducible PoC for validated exploits (EXPL-03)
6. Enforces "no exploit, no report" evidence validation (EXPL-04)
"""

import asyncclick as click
import structlog
from dataclasses import dataclass, field
from typing import Any

from scanner.agents.base import BaseAgent
from scanner.core.llm.tools import RiskLevel
from scanner.core.output import Evidence, Finding, SourceType
from scanner.core.persistence.database import get_session
from scanner.core.safety.approval import (
    ApprovalDecision,
    execute_tool_with_approval,
    request_approval,
)

logger = structlog.get_logger()


@dataclass
class ExploitStep:
    """Single step in an exploit chain.

    Attributes:
        description: Human-readable description of what this step does
        tool_name: Name of the tool to execute
        tool_params: Parameters to pass to the tool
        risk_level: Risk classification (SAFE/MODERATE/DESTRUCTIVE)
        blast_radius: Human-readable impact description
        affected_systems: List of systems/data that could be affected
        reversible: Whether the operation can be undone
    """

    description: str
    tool_name: str
    tool_params: dict
    risk_level: RiskLevel
    blast_radius: str
    affected_systems: list[str]
    reversible: bool


@dataclass
class ExploitChain:
    """Multi-step exploit chain suggested based on vulnerability finding.

    Attributes:
        finding: The vulnerability finding being exploited
        steps: Ordered list of exploitation steps
        objective: What the chain aims to demonstrate
    """

    finding: Finding
    steps: list[ExploitStep]
    objective: str


@dataclass
class ExploitResult:
    """Result of executing an exploit chain.

    Attributes:
        chain: The exploit chain that was executed
        steps_executed: Number of steps that were executed
        steps_total: Total number of steps in the chain
        poc: Reproducible proof-of-concept string (None if not validated)
        evidence_validated: Whether the exploit evidence passed validation
        raw_results: Per-step execution results
        confidence: "confirmed" if validated, "unconfirmed" otherwise
    """

    chain: ExploitChain
    steps_executed: int
    steps_total: int
    poc: str | None
    evidence_validated: bool
    raw_results: list[dict]
    confidence: str


class ExploitAgent(BaseAgent):
    """Guided exploitation agent (EXPL-01 through EXPL-04).

    Implements multi-step exploitation with:
    - Chain suggestion based on vulnerability type
    - Blast radius display before each destructive step
    - User approval workflow for moderate/destructive operations
    - Evidence validation ("no exploit, no report")
    - Reproducible PoC generation for confirmed exploits

    Example:
        >>> agent = ExploitAgent(session_id="test-session")
        >>> findings = [...]  # From VulnAgent
        >>> results = await agent.execute(findings)
        >>> for result in results:
        ...     if result.evidence_validated:
        ...         print(f"Confirmed: {result.poc}")
    """

    async def execute(self, findings: list[Finding]) -> list[ExploitResult]:
        """Execute guided exploitation on vulnerability findings.

        Pipeline for each exploitable finding:
        1. Suggest exploit chain based on finding type
        2. For each step in chain:
           - Display blast radius
           - Request approval if moderate/destructive
           - Execute if approved
           - Stop chain if denied
        3. Validate evidence from execution results
        4. Generate PoC if evidence validated

        Args:
            findings: List of vulnerability findings to exploit

        Returns:
            List of ExploitResult objects, one per finding
        """
        results = []

        await self.audit("exploit_session_start", {
            "finding_count": len(findings),
            "finding_titles": [f.title for f in findings]
        })

        for finding in findings:
            self.log.info("exploit_finding", finding=finding.title)

            # Generate exploit chain for this finding
            chain = await self._suggest_chain(finding)

            await self.audit("exploit_chain_suggested", {
                "finding": finding.title,
                "objective": chain.objective,
                "step_count": len(chain.steps)
            })

            # Execute chain step by step
            raw_results = []
            steps_executed = 0
            chain_stopped = False

            for idx, step in enumerate(chain.steps, 1):
                self.log.info("exploit_step_start", step=idx, total=len(chain.steps))

                # Display blast radius to user
                self._display_blast_radius(step, idx, len(chain.steps))

                # Execute step with approval workflow
                step_result = await self._execute_step(step)

                await self.audit("exploit_step_complete", {
                    "step": idx,
                    "description": step.description,
                    "status": step_result.get("status", "success"),
                    "denied": step_result.get("error") == "User denied approval"
                })

                # Check if user denied
                if step_result.get("error") == "User denied approval":
                    self.log.info("exploit_chain_stopped", reason="user_denied", step=idx)
                    chain_stopped = True
                    break

                raw_results.append(step_result)
                steps_executed += 1

            # Validate evidence from execution results
            evidence_validated = self._validate_evidence(raw_results)

            # Generate PoC if evidence validated
            poc = None
            if evidence_validated:
                poc = self._generate_poc(chain, raw_results)

            confidence = "confirmed" if evidence_validated else "unconfirmed"

            result = ExploitResult(
                chain=chain,
                steps_executed=steps_executed,
                steps_total=len(chain.steps),
                poc=poc,
                evidence_validated=evidence_validated,
                raw_results=raw_results,
                confidence=confidence
            )

            await self.audit("exploit_chain_complete", {
                "finding": finding.title,
                "steps_executed": steps_executed,
                "steps_total": len(chain.steps),
                "evidence_validated": evidence_validated,
                "confidence": confidence
            })

            results.append(result)

        await self.audit("exploit_session_complete", {
            "total_results": len(results),
            "confirmed": sum(1 for r in results if r.evidence_validated)
        })

        return results

    async def _suggest_chain(self, finding: Finding) -> ExploitChain:
        """Suggest exploit chain based on finding type.

        Currently deterministic based on vulnerability type. Phase 4 will
        add LLM-based chain suggestion for more sophisticated exploitation.

        Args:
            finding: The vulnerability finding

        Returns:
            ExploitChain with steps appropriate for the vulnerability type
        """
        # Normalize title to detect vulnerability type
        title_lower = finding.title.lower()

        # SQL Injection chain
        if "sql" in title_lower and "injection" in title_lower:
            return ExploitChain(
                finding=finding,
                objective="Demonstrate SQL injection vulnerability and extract database information",
                steps=[
                    ExploitStep(
                        description="Verify SQL injection with safe payload",
                        tool_name="sqlmap",
                        tool_params={"action": "verify", "technique": "boolean"},
                        risk_level=RiskLevel.SAFE,
                        blast_radius="Read-only verification query, no data modification",
                        affected_systems=["Target database (read-only query)"],
                        reversible=True
                    ),
                    ExploitStep(
                        description="Extract database schema and table names",
                        tool_name="sqlmap",
                        tool_params={"action": "enumerate", "target": "schema"},
                        risk_level=RiskLevel.MODERATE,
                        blast_radius="Queries database metadata (table names, columns). May appear in logs.",
                        affected_systems=["Target database (metadata enumeration)", "Application logs"],
                        reversible=True
                    ),
                    ExploitStep(
                        description="Dump sensitive data from identified tables",
                        tool_name="sqlmap",
                        tool_params={"action": "dump", "target": "data"},
                        risk_level=RiskLevel.DESTRUCTIVE,
                        blast_radius="EXTRACTS REAL DATA from database. May include user credentials, PII, or business data.",
                        affected_systems=["Target database (data extraction)", "Application logs", "IDS/IPS alerts"],
                        reversible=False
                    )
                ]
            )

        # XSS (Reflected or Stored) chain
        elif "xss" in title_lower or "cross-site scripting" in title_lower:
            risk = RiskLevel.MODERATE if "stored" in title_lower else RiskLevel.MODERATE
            return ExploitChain(
                finding=finding,
                objective="Demonstrate XSS vulnerability with proof-of-concept payload",
                steps=[
                    ExploitStep(
                        description="Verify XSS reflection with harmless payload",
                        tool_name="xsstrike",
                        tool_params={"action": "verify", "payload": "<script>console.log('test')</script>"},
                        risk_level=RiskLevel.SAFE,
                        blast_radius="Injects harmless console.log() for reflection verification",
                        affected_systems=["Target web page (temporary reflection)"],
                        reversible=True
                    ),
                    ExploitStep(
                        description="Craft proof-of-concept payload that demonstrates impact",
                        tool_name="xsstrike",
                        tool_params={"action": "craft", "payload_type": "alert"},
                        risk_level=RiskLevel.SAFE,
                        blast_radius="Generates payload string, no execution yet",
                        affected_systems=["None (payload generation only)"],
                        reversible=True
                    ),
                    ExploitStep(
                        description="Test payload execution in target context",
                        tool_name="xsstrike",
                        tool_params={"action": "test", "execute": True},
                        risk_level=risk,
                        blast_radius="Executes JavaScript payload in browser context. May trigger alerts or affect other users if stored.",
                        affected_systems=["Target web page", "Other users (if stored XSS)", "Application logs"],
                        reversible="stored" not in title_lower
                    )
                ]
            )

        # Command Injection chain
        elif "command" in title_lower and "injection" in title_lower:
            return ExploitChain(
                finding=finding,
                objective="Demonstrate command injection with system command execution",
                steps=[
                    ExploitStep(
                        description="Verify command injection with safe read-only command",
                        tool_name="commix",
                        tool_params={"action": "verify", "command": "whoami"},
                        risk_level=RiskLevel.SAFE,
                        blast_radius="Executes 'whoami' command to verify injection",
                        affected_systems=["Target server (read-only command)"],
                        reversible=True
                    ),
                    ExploitStep(
                        description="Execute proof-of-concept command demonstrating full access",
                        tool_name="commix",
                        tool_params={"action": "execute", "command": "id && uname -a"},
                        risk_level=RiskLevel.DESTRUCTIVE,
                        blast_radius="EXECUTES ARBITRARY COMMANDS on target server. Full system access demonstrated.",
                        affected_systems=["Target server (command execution)", "System logs", "IDS/IPS alerts"],
                        reversible=False
                    )
                ]
            )

        # Security headers or other low-risk findings
        else:
            return ExploitChain(
                finding=finding,
                objective="Verify the security issue exists",
                steps=[
                    ExploitStep(
                        description="Verify security issue with read-only check",
                        tool_name="verify",
                        tool_params={"action": "check"},
                        risk_level=RiskLevel.SAFE,
                        blast_radius="Read-only verification, no modifications",
                        affected_systems=["Target system (read-only)"],
                        reversible=True
                    )
                ]
            )

    def _display_blast_radius(self, step: ExploitStep, step_num: int, total_steps: int):
        """Display blast radius information to user via CLI.

        Args:
            step: The exploit step to display
            step_num: Current step number (1-indexed)
            total_steps: Total number of steps in chain
        """
        click.echo("\n" + "=" * 60)
        click.echo(f"Step {step_num}/{total_steps}: {step.description}")
        click.echo("=" * 60)
        click.echo(f"Risk Level: {step.risk_level.value.upper()}")
        click.echo(f"\nBlast Radius:")
        click.echo(f"  {step.blast_radius}")
        click.echo(f"\nAffected Systems:")
        for system in step.affected_systems:
            click.echo(f"  - {system}")

        reversible_text = "Yes" if step.reversible else "NO - PERMANENT"
        click.echo(f"\nReversible: {reversible_text}")
        click.echo("=" * 60 + "\n")

    async def _execute_step(self, step: ExploitStep) -> dict:
        """Execute a single exploit step with approval workflow.

        SAFE steps auto-execute. MODERATE and DESTRUCTIVE steps require approval.

        Args:
            step: The exploit step to execute

        Returns:
            Result dictionary with status, output, and any errors
        """
        # For now, we mock the actual tool execution since the real tools
        # (sqlmap, xsstrike, commix) are complex and would need proper
        # target infrastructure. The approval workflow is the key piece.

        # If step is SAFE, auto-execute
        if step.risk_level == RiskLevel.SAFE:
            self.log.info("auto_execute_safe_step", tool=step.tool_name)
            return await self._mock_tool_execution(step)

        # For MODERATE/DESTRUCTIVE, request approval
        async with get_session() as session:
            # Create a minimal ToolDefinition for approval workflow
            from scanner.core.llm.tools import ToolDefinition

            tool_def = ToolDefinition(
                name=step.tool_name,
                description=step.description,
                risk_level=step.risk_level,
                input_schema={
                    "type": "object",
                    "properties": step.tool_params,
                    "required": []
                }
            )

            # Request approval
            decision, final_params = await request_approval(
                tool_name=step.tool_name,
                tool_input=step.tool_params,
                risk_level=step.risk_level,
                context={
                    "session_id": self.session_id,
                    "description": step.description,
                    "blast_radius": step.blast_radius
                }
            )

            # Log approval decision
            await self.audit("step_approval_decision", {
                "tool": step.tool_name,
                "decision": decision.value,
                "risk_level": step.risk_level.value
            })

            if decision == ApprovalDecision.DENY:
                return {"error": "User denied approval", "tool": step.tool_name}

            # Execute with approved/modified parameters
            return await self._mock_tool_execution(step, final_params)

    async def _mock_tool_execution(self, step: ExploitStep, params: dict | None = None) -> dict:
        """Mock tool execution for testing (will be replaced with real tool calls in Phase 4).

        Args:
            step: The exploit step to execute
            params: Tool parameters (defaults to step.tool_params)

        Returns:
            Mock result dictionary
        """
        params = params or step.tool_params

        # Simulate tool execution with realistic output
        if step.tool_name == "sqlmap":
            if params.get("action") == "verify":
                return {
                    "status": "success",
                    "vulnerable": True,
                    "raw_output": "sqlmap identified the following injection point(s): Parameter: id (GET)\n Type: boolean-based blind"
                }
            elif params.get("action") == "enumerate":
                return {
                    "status": "success",
                    "schema": ["users", "posts", "sessions"],
                    "raw_output": "available databases: [3]\n[*] users\n[*] posts\n[*] sessions"
                }
            elif params.get("action") == "dump":
                return {
                    "status": "success",
                    "data": {"users": 150, "records_extracted": 10},
                    "raw_output": "Database: users\nTable: user_accounts\n[10 entries]\nid | username | email"
                }

        elif step.tool_name == "xsstrike":
            if params.get("action") == "verify":
                return {
                    "status": "success",
                    "reflected": True,
                    "raw_output": "Payload reflected in response without encoding"
                }
            elif params.get("action") == "craft":
                return {
                    "status": "success",
                    "payload": "<script>alert(document.domain)</script>",
                    "raw_output": "Generated payload: <script>alert(document.domain)</script>"
                }
            elif params.get("action") == "test":
                return {
                    "status": "success",
                    "executed": True,
                    "raw_output": "Payload executed successfully in browser context"
                }

        elif step.tool_name == "commix":
            if params.get("action") == "verify":
                return {
                    "status": "success",
                    "injectable": True,
                    "raw_output": "The target is vulnerable to command injection\nOutput: www-data"
                }
            elif params.get("action") == "execute":
                return {
                    "status": "success",
                    "command_output": "uid=33(www-data) gid=33(www-data) groups=33(www-data)\nLinux webserver 5.4.0",
                    "raw_output": "Command executed: id && uname -a\nuid=33(www-data) gid=33(www-data)"
                }

        else:  # Generic verification
            return {
                "status": "success",
                "verified": True,
                "raw_output": "Security issue verified"
            }

    def _validate_evidence(self, results: list[dict]) -> bool:
        """Validate evidence from exploit execution results (EXPL-04).

        Implements "no exploit, no report" - evidence must have:
        1. At least one result with non-empty raw_output
        2. Success indicators (not just errors)
        3. Tool-confirmed data

        Args:
            results: List of per-step execution results

        Returns:
            True if evidence is validated, False otherwise
        """
        if not results:
            return False

        # Must have at least one successful result
        successful_results = [r for r in results if r.get("status") == "success"]
        if not successful_results:
            return False

        # Must have actual tool output (not just errors)
        has_output = any(
            r.get("raw_output") and len(r.get("raw_output", "")) > 0
            for r in successful_results
        )
        if not has_output:
            return False

        # Check for success indicators (not just errors)
        has_success_indicators = any(
            any(
                key in r and r[key] not in (None, "", [], {}, False)
                for key in ["vulnerable", "injectable", "reflected", "executed",
                           "schema", "data", "command_output", "verified"]
            )
            for r in successful_results
        )

        return has_success_indicators

    def _generate_poc(self, chain: ExploitChain, results: list[dict]) -> str | None:
        """Generate reproducible proof-of-concept string (EXPL-03).

        Creates a copy-paste ready PoC command or URL that demonstrates
        the vulnerability.

        Args:
            chain: The exploit chain that was executed
            results: Per-step execution results

        Returns:
            PoC string as markdown code block, or None if evidence not validated
        """
        if not self._validate_evidence(results):
            return None

        finding_title = chain.finding.title.lower()

        # SQL Injection PoC
        if "sql" in finding_title and "injection" in finding_title:
            # Extract injection details from results
            vulnerable_param = "id"  # Would be extracted from actual tool output
            target_url = "http://target.example.com/page"  # From finding evidence

            poc = f"""```bash
# SQL Injection Proof-of-Concept
# Vulnerability: {chain.finding.title}
# Objective: {chain.objective}

# Step 1: Verify injection with boolean-based payload
curl "{target_url}?{vulnerable_param}=1+AND+1=1"  # Should return normal response
curl "{target_url}?{vulnerable_param}=1+AND+1=2"  # Should return different response

# Step 2: Extract database schema
sqlmap -u "{target_url}?{vulnerable_param}=1" --batch --dbs

# Step 3: Dump tables (use with caution)
sqlmap -u "{target_url}?{vulnerable_param}=1" --batch -D database_name --tables

# Evidence: {results[0].get('raw_output', 'Tool confirmed vulnerability')}
```"""
            return poc

        # XSS PoC
        elif "xss" in finding_title:
            payload = results[1].get("payload", "<script>alert(document.domain)</script>") if len(results) > 1 else "<script>alert(1)</script>"
            target_url = "http://target.example.com/search"  # From finding evidence

            poc = f"""```html
<!-- XSS Proof-of-Concept -->
<!-- Vulnerability: {chain.finding.title} -->
<!-- Objective: {chain.objective} -->

<!-- Step 1: Verify reflection -->
{target_url}?q=<script>console.log('test')</script>

<!-- Step 2: Execute payload -->
{target_url}?q={payload}

<!-- Evidence: Payload reflected without encoding -->
<!-- Browser will execute JavaScript: {payload} -->
```"""
            return poc

        # Command Injection PoC
        elif "command" in finding_title and "injection" in finding_title:
            target_url = "http://target.example.com/api/ping"

            poc = f"""```bash
# Command Injection Proof-of-Concept
# Vulnerability: {chain.finding.title}
# Objective: {chain.objective}

# Step 1: Verify injection with safe command
curl -X POST "{target_url}" -d "host=127.0.0.1;whoami"

# Step 2: Demonstrate full access
curl -X POST "{target_url}" -d "host=127.0.0.1;id && uname -a"

# Evidence: {results[0].get('raw_output', 'Command injection confirmed')}
```"""
            return poc

        # Generic PoC for other vulnerabilities
        else:
            poc = f"""```text
Proof-of-Concept for {chain.finding.title}

Objective: {chain.objective}

Steps:
"""
            for idx, step in enumerate(chain.steps, 1):
                result = results[idx - 1] if idx - 1 < len(results) else {}
                poc += f"{idx}. {step.description}\n"
                if result.get("raw_output"):
                    poc += f"   Result: {result['raw_output'][:100]}...\n"

            poc += "```"
            return poc
